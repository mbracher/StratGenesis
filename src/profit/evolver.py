"""Evolutionary engine for strategy optimization.

This module contains the ProfitEvolver class which orchestrates the
evolution loop for trading strategy optimization using LLMs.
"""

import inspect
import json
import random
import shutil
import traceback
from datetime import datetime
from pathlib import Path

import numpy as np
import pandas as pd
from backtesting import Backtest, Strategy

from profit.llm_interface import LLMClient
from profit.strategies import (
    BollingerMeanReversion,
    CCIStrategy,
    EMACrossover,
    MACDStrategy,
    WilliamsRStrategy,
    RandomStrategy,
    BuyAndHoldStrategy,
)


class StrategyPersister:
    """Handles saving evolved strategies to disk."""

    def __init__(self, output_dir: str = "evolved_strategies"):
        """Initialize the persister.

        Args:
            output_dir: Base directory for saving strategies.
        """
        self.output_dir = Path(output_dir)
        self.run_dir: Path | None = None
        self.run_id: str | None = None

    def start_run(
        self,
        seed_strategy_name: str,
        analyst_provider: str,
        analyst_model: str,
        coder_provider: str,
        coder_model: str,
    ) -> Path:
        """Initialize a new run directory.

        Args:
            seed_strategy_name: Name of the seed strategy being evolved.
            analyst_provider: LLM provider for analysis role.
            analyst_model: LLM model for analysis role.
            coder_provider: LLM provider for coding role.
            coder_model: LLM model for coding role.

        Returns:
            Path to the run directory.
        """
        self.run_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.run_dir = self.output_dir / f"run_{self.run_id}"
        self.run_dir.mkdir(parents=True, exist_ok=True)

        run_info = {
            "run_id": self.run_id,
            "started_at": datetime.now().isoformat(),
            "seed_strategy": seed_strategy_name,
            "llm_config": {
                "analyst": {
                    "provider": analyst_provider,
                    "model": analyst_model,
                },
                "coder": {
                    "provider": coder_provider,
                    "model": coder_model,
                },
            },
            "folds": [],
        }
        self._write_json(self.run_dir / "run_summary.json", run_info)

        return self.run_dir

    def save_strategy(
        self,
        strategy_class,
        source_code: str,
        fold: int,
        generation: int,
        metrics: dict,
        parent_name: str,
        improvement_proposal: str,
    ) -> Path:
        """Save an evolved strategy to disk.

        Args:
            strategy_class: The strategy class object.
            source_code: Complete Python source code of the strategy.
            fold: Walk-forward fold number (1-indexed).
            generation: Evolution generation number.
            metrics: Performance metrics dict.
            parent_name: Name of the parent strategy.
            improvement_proposal: The LLM's improvement proposal text.

        Returns:
            Path to the saved strategy file.
        """
        fold_dir = self.run_dir / f"fold_{fold}"
        fold_dir.mkdir(exist_ok=True)

        class_name = strategy_class.__name__

        # Save source code as .py file
        strategy_path = fold_dir / f"{class_name}.py"
        header = self._generate_header(class_name, fold, generation, metrics)
        self._write_file(strategy_path, header + source_code)

        # Save metadata as .json file
        metadata = {
            "class_name": class_name,
            "fold": fold,
            "generation": generation,
            "parent_strategy": parent_name,
            "improvement_proposal": improvement_proposal,
            "metrics": metrics,
            "saved_at": datetime.now().isoformat(),
        }
        self._write_json(fold_dir / f"{class_name}.json", metadata)

        return strategy_path

    def _generate_header(
        self, class_name: str, fold: int, generation: int, metrics: dict
    ) -> str:
        """Generate a header comment for the strategy file."""
        ann_return = metrics.get("AnnReturn%")
        sharpe = metrics.get("Sharpe")
        ann_str = f"{ann_return:.2f}%" if ann_return is not None else "N/A"
        sharpe_str = f"{sharpe:.2f}" if sharpe is not None else "N/A"

        return f'''"""Evolved Strategy: {class_name}

Generated by ProFiT evolutionary optimization.
Fold: {fold} | Generation: {generation}
Annualized Return: {ann_str}
Sharpe Ratio: {sharpe_str}

Auto-generated - do not edit manually.
"""

import numpy as np
import pandas as pd
from backtesting import Strategy


'''

    def save_fold_best(
        self, fold: int, strategy_class, source_code: str, metrics: dict
    ) -> Path:
        """Save the best strategy for a fold.

        Args:
            fold: Fold number.
            strategy_class: Best strategy class for this fold.
            source_code: Source code of the strategy.
            metrics: Performance metrics.

        Returns:
            Path to the best strategy file.
        """
        fold_dir = self.run_dir / f"fold_{fold}"
        fold_dir.mkdir(exist_ok=True)
        best_path = fold_dir / "best_strategy.py"

        ann_return = metrics.get("AnnReturn%")
        sharpe = metrics.get("Sharpe")
        ann_str = f"{ann_return:.2f}%" if ann_return is not None else "N/A"
        sharpe_str = f"{sharpe:.2f}" if sharpe is not None else "N/A"

        header = f'''"""Best Strategy for Fold {fold}

Original class: {strategy_class.__name__}
Annualized Return: {ann_str}
Sharpe Ratio: {sharpe_str}
"""

import numpy as np
import pandas as pd
from backtesting import Strategy


'''
        self._write_file(best_path, header + source_code)
        return best_path

    def finalize_run(self, results: list[dict]) -> Path:
        """Finalize the run and save summary.

        Args:
            results: List of per-fold result dictionaries.

        Returns:
            Path to the run summary file.
        """
        summary_path = self.run_dir / "run_summary.json"
        summary = self._read_json(summary_path)

        # Add fold results
        for res in results:
            fold_info = {
                "fold": res["fold"],
                "best_strategy": res["strategy"].__name__,
                "ann_return": res["ann_return"],
                "sharpe": res["sharpe"],
                "expectancy": res["expectancy"],
                "vs_random": res["ann_return"] - res["random_return"],
                "vs_buy_hold": res["ann_return"] - res["buy_hold_return"],
            }
            summary["folds"].append(fold_info)

        # Add aggregate stats
        summary["completed_at"] = datetime.now().isoformat()
        summary["avg_ann_return"] = float(np.mean([r["ann_return"] for r in results]))
        summary["avg_sharpe"] = float(np.mean([r["sharpe"] for r in results]))
        summary["best_fold"] = max(results, key=lambda r: r["ann_return"])["fold"]

        self._write_json(summary_path, summary)

        # Copy best overall strategy
        best_result = max(results, key=lambda r: r["ann_return"])
        best_fold_dir = self.run_dir / f"fold_{best_result['fold']}"
        best_src = best_fold_dir / "best_strategy.py"
        if best_src.exists():
            shutil.copy(best_src, self.run_dir / "best_overall.py")

        return summary_path

    def _write_file(self, path: Path, content: str) -> None:
        """Write string content to file."""
        path.write_text(content)

    def _write_json(self, path: Path, data: dict) -> None:
        """Write dict as JSON to file."""
        path.write_text(json.dumps(data, indent=2))

    def _read_json(self, path: Path) -> dict:
        """Read JSON file as dict."""
        return json.loads(path.read_text())


def load_strategy(strategy_path: str):
    """Load a saved strategy from a .py file.

    Args:
        strategy_path: Path to the saved strategy Python file.

    Returns:
        The strategy class ready for backtesting.

    Example:
        >>> strat = load_strategy("evolved_strategies/run_20250114/fold_1/best_strategy.py")
        >>> bt = Backtest(data, strat, cash=10000)
        >>> bt.run()
    """
    import importlib.util

    path = Path(strategy_path)
    spec = importlib.util.spec_from_file_location(path.stem, path)
    module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(module)

    # Find the Strategy subclass in the module
    for name, obj in vars(module).items():
        if isinstance(obj, type) and issubclass(obj, Strategy) and obj is not Strategy:
            return obj

    raise ValueError(f"No Strategy subclass found in {strategy_path}")


class ProfitEvolver:
    """Evolutionary search engine for trading strategy optimization.

    Uses LLM-guided code mutation and walk-forward validation to evolve
    strategies that adapt to changing market conditions.
    """

    def __init__(
        self,
        llm_client: LLMClient,
        initial_capital: float = 10000,
        commission: float = 0.002,
        exclusive_orders: bool = True,
        output_dir: str | None = "evolved_strategies",
        finalize_trades: bool = True,
    ):
        """Initialize the ProfitEvolver.

        Args:
            llm_client: An instance of LLMClient for generating strategy mutations.
            initial_capital: Starting cash for backtests (default: $10,000).
            commission: Per-trade commission rate (default: 0.002 = 0.2%).
            exclusive_orders: If True, no overlapping long/short positions.
            output_dir: Directory to save evolved strategies. Set to None to disable.
            finalize_trades: If True, auto-close open trades at backtest end.
        """
        self.llm = llm_client
        self.initial_capital = initial_capital
        self.commission = commission
        self.exclusive_orders = exclusive_orders
        self.finalize_trades = finalize_trades
        self.persister = StrategyPersister(output_dir) if output_dir else None

    def run_backtest(self, strategy_class, data: pd.DataFrame) -> tuple[dict, pd.Series]:
        """Run a backtest on given data with specified strategy class.

        Args:
            strategy_class: A backtesting.Strategy subclass to evaluate.
            data: DataFrame with OHLCV data and datetime index.

        Returns:
            A tuple of (metrics, result) where:
            - metrics: dict with key performance metrics (AnnReturn%, Sharpe, Expectancy%, Trades)
            - result: Full backtesting.py result Series
        """
        bt = Backtest(
            data,
            strategy_class,
            cash=self.initial_capital,
            commission=self.commission,
            exclusive_orders=self.exclusive_orders,
            finalize_trades=self.finalize_trades,
        )
        result = bt.run()

        # Extract key metrics
        metrics = {
            "AnnReturn%": result.get("Return (Ann.) [%]", None),
            "Sharpe": result.get("Sharpe Ratio", None),
            "Expectancy%": result.get("Expectancy [%]", None),
            "Trades": result.get("# Trades", None),
        }
        return metrics, result

    def prepare_folds(
        self, full_data: pd.DataFrame, n_folds: int = 5
    ) -> list[tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]]:
        """Split the full_data DataFrame into train/validation/test folds.

        Implements walk-forward validation with:
        - Training period: 2.5 years (30 months)
        - Validation period: 6 months
        - Test period: 6 months
        - Gap between periods: 10 days (prevents look-ahead bias)

        Args:
            full_data: Complete DataFrame with datetime index and OHLCV columns.
            n_folds: Number of walk-forward folds (default: 5).

        Returns:
            List of (train_df, val_df, test_df) tuples for each fold.
        """
        fold_splits = []
        data_index = full_data.index
        start_date = data_index.min()

        for fold in range(n_folds):
            # Train period: 2.5 years (2 years + 6 months) from current start
            train_end = start_date + pd.DateOffset(years=2) + pd.DateOffset(months=6)

            # Validation start: 10 days after train end (gap)
            val_start = train_end + pd.DateOffset(days=10)
            # Validation end: 6 months after train end
            val_end = train_end + pd.DateOffset(months=6)

            # Test start: 10 days after validation end (gap)
            test_start = val_end + pd.DateOffset(days=10)
            # Test end: 6 months after validation end
            test_end = val_end + pd.DateOffset(months=6)

            # Slice data for each period
            train = full_data[start_date:train_end]
            val = full_data[val_start:val_end]
            test = full_data[test_start:test_end]

            # Stop if we run out of data
            if len(test) == 0:
                break

            fold_splits.append((train, val, test))

            # Move start_date to end of this test period for next fold
            start_date = test_end

        return fold_splits

    def _random_index(self, n: int) -> int:
        """Return a random index in range [0, n).

        Args:
            n: Upper bound (exclusive).

        Returns:
            Random integer in [0, n).
        """
        return random.randrange(n)

    def evolve_strategy(
        self,
        strategy_class,
        train_data: pd.DataFrame,
        val_data: pd.DataFrame,
        max_iters: int = 15,
        fold: int = 1,
    ):
        """Evolve a strategy using LLM-guided mutations.

        Implements the ProFiT evolutionary loop with MAS (Minimum Acceptable Score)
        threshold. New strategies must meet or exceed MAS to be accepted into the
        population.

        Args:
            strategy_class: Seed strategy class to evolve.
            train_data: Training data (for context, not directly used in fitness).
            val_data: Validation data for fitness evaluation.
            max_iters: Maximum number of evolution generations (default: 15).
            fold: Walk-forward fold number for persistence (default: 1).

        Returns:
            Tuple of (best_strategy_class, best_perf, best_code) where:
            - best_strategy_class: The evolved strategy class with highest fitness
            - best_perf: Performance (annualized return %) on validation
            - best_code: Source code of the best strategy
        """
        # 1. Compute baseline performance P0 on validation set
        _, base_result = self.run_backtest(strategy_class, val_data)
        P0 = base_result["Return (Ann.) [%]"]
        print(
            f"Initial strategy {strategy_class.__name__} baseline annualized return "
            f"on validation: {P0:.2f}%"
        )

        # 2. Set MAS = P0 (Minimum Acceptable Score)
        MAS = P0

        # Get source code of the seed strategy
        seed_code = inspect.getsource(strategy_class)

        # Archive of viable strategies (as tuples of class, performance, and source code)
        # We store source code to support dynamically generated strategies
        population = [(strategy_class, P0, seed_code)]
        best_perf = P0
        best_strategy_class = strategy_class
        best_strategy_code = seed_code

        # Build exec namespace with necessary imports for generated code
        exec_globals = {
            "Strategy": Strategy,
            "pd": pd,
            "np": np,
        }

        # 4. Evolution loop
        for gen in range(1, max_iters + 1):
            print(
                f"\nGeneration {gen}: Current population size = {len(population)}. "
                "Selecting a strategy to mutate..."
            )

            # 5. Select a strategy from population (random selection for diversity)
            parent_class, parent_perf, parent_code = population[self._random_index(len(population))]
            print(
                f"Selected parent strategy '{parent_class.__name__}' with validation "
                f"return {parent_perf:.2f}% for mutation."
            )

            # 6. Prompt LLM A for improvement proposal
            improvement = self.llm.generate_improvement(
                parent_code, f"AnnReturn={parent_perf:.2f}%"
            )
            print(f"LLM suggested improvement: {improvement}")

            # 7. Prompt LLM B to synthesize modified strategy code
            new_code = self.llm.generate_strategy_code(parent_code, improvement)

            # Give the new strategy a unique name by generation
            new_class_name = f"{parent_class.__name__}_Gen{gen}"

            # Replace class name in code to avoid collisions
            if new_code.startswith("class"):
                new_code = new_code.replace(parent_class.__name__, new_class_name, 1)

            # 8-11. Try to compile and backtest with repair loop
            success = False
            NewStrategyClass = None
            res = None

            for attempt in range(1, 11):  # up to 10 repair attempts
                try:
                    # Dynamically define the new strategy class from code
                    namespace = {}
                    exec(new_code, exec_globals, namespace)
                    NewStrategyClass = namespace[new_class_name]

                    # Run backtest on validation data to get performance
                    _, res = self.run_backtest(NewStrategyClass, val_data)
                    success = True
                    break

                except Exception as e:
                    tb = traceback.format_exc()
                    print(f"Attempt {attempt}: Strategy code failed with error: {e}")

                    if attempt < 10:
                        # 11. Prompt LLM B with traceback to fix code
                        new_code = self.llm.fix_code(new_code, tb)

                        # Ensure the class name persists in the corrected code
                        if new_class_name not in new_code:
                            new_code = new_code.replace(
                                parent_class.__name__, new_class_name, 1
                            )
                    else:
                        print("Max repair attempts reached. Discarding this mutation.")

            if not success:
                continue  # Move to next generation

            # 14. Compute fitness of new strategy
            P_new = res["Return (Ann.) [%]"]
            print(
                f"New strategy variant '{new_class_name}' achieved validation "
                f"annual return {P_new:.2f}%"
            )

            # 15-18. Check against MAS threshold
            if P_new is not None and P_new >= MAS:
                # Accept new strategy into population (with source code)
                population.append((NewStrategyClass, P_new, new_code))
                print(
                    f"Accepted new strategy (>= MAS={MAS:.2f}%). "
                    f"Population size now {len(population)}."
                )

                # Persist the accepted strategy
                if self.persister and self.persister.run_dir:
                    metrics = {
                        "AnnReturn%": P_new,
                        "Sharpe": res.get("Sharpe Ratio"),
                        "Expectancy%": res.get("Expectancy [%]"),
                        "Trades": res.get("# Trades"),
                    }
                    self.persister.save_strategy(
                        strategy_class=NewStrategyClass,
                        source_code=new_code,
                        fold=fold,
                        generation=gen,
                        metrics=metrics,
                        parent_name=parent_class.__name__,
                        improvement_proposal=improvement,
                    )

                # Update best if this is highest so far
                if P_new > best_perf:
                    best_perf = P_new
                    best_strategy_class = NewStrategyClass
                    best_strategy_code = new_code
            else:
                print(f"Discarded new strategy (did not meet MAS={MAS:.2f}%).")

        print(
            f"\nEvolution complete. Best strategy '{best_strategy_class.__name__}' "
            f"validation return = {best_perf:.2f}%."
        )
        return best_strategy_class, best_perf, best_strategy_code

    def walk_forward_optimize(
        self, full_data: pd.DataFrame, strategy_class, n_folds: int = 5
    ) -> list[dict]:
        """Perform walk-forward optimization across multiple folds.

        Evolves the strategy on each training/validation set, then evaluates
        on the test set. Compares performance against baseline strategies.

        Args:
            full_data: Complete historical DataFrame with datetime index and OHLCV columns.
            strategy_class: Seed strategy class to evolve.
            n_folds: Number of walk-forward folds (default: 5).

        Returns:
            List of per-fold result dictionaries containing:
            - fold: Fold number (1-indexed)
            - strategy: Best evolved strategy class
            - ann_return: Annualized return on test (%)
            - sharpe: Sharpe ratio on test
            - expectancy: Expectancy on test (%)
            - random_return: Random baseline return (%)
            - buy_hold_return: Buy-and-hold baseline return (%)
        """
        # Start persistence run
        if self.persister:
            run_dir = self.persister.start_run(
                seed_strategy_name=strategy_class.__name__,
                analyst_provider=self.llm.analyst_provider,
                analyst_model=self.llm.analyst_model,
                coder_provider=self.llm.coder_provider,
                coder_model=self.llm.coder_model,
            )
            print(f"Saving evolved strategies to: {run_dir}")

        folds = self.prepare_folds(full_data, n_folds=n_folds)
        results = []

        for i, (train, val, test) in enumerate(folds, start=1):
            print(f"\n=== Fold {i} ===")
            print(f"Training period: {train.index[0]} to {train.index[-1]}")
            print(f"Validation period: {val.index[0]} to {val.index[-1]}")
            print(f"Test period: {test.index[0]} to {test.index[-1]}")

            # Evolve strategy on this fold's data
            best_strat, _, best_code = self.evolve_strategy(strategy_class, train, val, fold=i)

            # Evaluate best strategy on test set
            metrics, res = self.run_backtest(best_strat, test)
            ann_return = metrics["AnnReturn%"]
            sharpe = metrics["Sharpe"]
            expectancy = metrics["Expectancy%"]
            print(
                f"Fold {i} Test Performance - Annualized Return: {ann_return:.2f}%, "
                f"Sharpe: {sharpe:.2f}, Expectancy: {expectancy:.2f}%"
            )

            # Save best strategy for this fold
            if self.persister:
                self.persister.save_fold_best(i, best_strat, best_code, metrics)

            # Also evaluate baselines on the test set for comparison
            _, res_rand = self.run_backtest(RandomStrategy, test)
            _, res_bh = self.run_backtest(BuyAndHoldStrategy, test)
            rand_return = res_rand["Return (Ann.) [%]"]
            bh_return = res_bh["Return (Ann.) [%]"]
            print(
                f"Fold {i} Baselines - Random Strat Return: {rand_return:.2f}%, "
                f"Buy&Hold Return: {bh_return:.2f}%"
            )

            results.append({
                "fold": i,
                "strategy": best_strat,
                "ann_return": ann_return,
                "sharpe": sharpe,
                "expectancy": expectancy,
                "random_return": rand_return,
                "buy_hold_return": bh_return,
            })

        # Summarize across folds
        avg_ret = np.mean([r["ann_return"] for r in results])
        avg_bh = np.mean([r["buy_hold_return"] for r in results])
        avg_rand = np.mean([r["random_return"] for r in results])

        print(f"\nAverage Annualized Return over {len(results)} folds: {avg_ret:.2f}%")
        print(f"Average Buy-and-Hold Return over {len(results)} folds: {avg_bh:.2f}%")
        print(f"Average Random Strategy Return over {len(results)} folds: {avg_rand:.2f}%")

        # Finalize persistence run
        if self.persister:
            summary_path = self.persister.finalize_run(results)
            print(f"\nRun summary saved to: {summary_path}")

        return results
